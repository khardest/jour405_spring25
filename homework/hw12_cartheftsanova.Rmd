---
title: "hw12_cartheftsanova"
output: html_document
---

---
title: "Prince George's County Car Theft Spike Analysis"
author: Keira Hardesty
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.width = 10, fig.height = 6)
```

## Introduction

This analysis examines the impact of a significant spike in car theft rates in 2023 in Prince George's County, and whether that spike has led to a sustained higher rate of car theft in the county. We'll use Analysis of Variance (ANOVA) to determine if theft rates differ significantly between pre-spike (before 2023), spike (2023), and post-spike (2024-present) periods.

## Data Preparation and Exploration

### Loading Libraries and Data

```{r load-libraries}
# Load required libraries
library(tidyverse)
library(lubridate)
```

```{r load-data}
# Import data
theft_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/car_thefts_month17_25.csv")

# Look at the first few rows
head(theft_data)

# Get a summary of the data
summary(theft_data)
```


### Get the data how we want it and calculate the rates

**Task 1** Replace REPLACE_ME with the variables you need to calculate the theft_rate (2 points)

```{r process-data}
# Calculate theft rate and create time period variable
theft_data <- theft_data |>
  mutate(
    date = as.Date(month),
    year = year(date),
    month_number = month(date),
    theft_rate = (total / population) * 100000,
    time_period = case_when(
      year < 2023 ~ "Pre-spike",
      year == 2023 ~ "Spike year",
      year > 2023 ~ "Post-spike"
    )
  )

# Create summary by time period
period_summary <- theft_data |>
  group_by(time_period) |>
  summarize(
    mean_thefts = mean(total),
    mean_rate = mean(theft_rate),
    median_rate = median(theft_rate),
    sd_rate = sd(theft_rate),
    n = n(),
    .groups = "drop"
  )

# Display the summary
knitr::kable(period_summary, digits = 2,
             caption = "Summary of Car Theft Rates by Time Period")
```

**Task 2** Describe the results of calculating the rates for each period. What do they suggest? (3 points)

Calculating the rates suggests that car thefts were table before the spike, increased dramatically in 2023 and then fell after the spike but remained higher than the pre spike rates. Pre 2023, the avg monthly theft rate was 23.19 per 100,000 people, then in 2023 it increased dramatically to 59.95 then fell to 43.32 after the spike. The standard deviation increased during all three periods, showing that post spike we see the most variability in car theft numbers. 


## Visualizing the Spike Pattern

### Time Series Plot

```{r time-series}
# Time series plot showing the spike pattern
ggplot(theft_data, aes(x = date, y = theft_rate)) +
  geom_line() +
  geom_smooth(method = "loess", span = 0.2) +
  geom_vline(xintercept = as.Date("2023-01-01"), linetype = "dashed", color = "red") +
  geom_vline(xintercept = as.Date("2024-01-01"), linetype = "dashed", color = "red") +
  annotate("text", x = as.Date("2023-07-01"), y = max(theft_data$theft_rate) * 0.9, 
           label = "Spike Year", color = "red") +
  labs(title = "Monthly Car Theft Rates (2017-2025) with Spike Highlighted",
       x = "Date", y = "Thefts per 100,000 Population") +
  theme_minimal()
```

**Task 3** Describe the output of this chart and then give it a better, more active title that provides the lede (3 points)

This chart shows the monthly car theft rates per 100,000 people from 2017 to 2025. The 2023 spike in car thefts is highlighted with the red lines. The chart shows how car thefts were low and stable til they peaked in 2023. Then, theft rates declined in 2024 but still remained higher than pre spike levels. 

Prince George's County car thefts: Soared in 2023 and have remained elevated since. 


Now let's take a look at average theft rates.

### Yearly Average Theft Rates

```{r yearly-means}
# Calculate yearly means
yearly_means <- theft_data |>
  group_by(year) |>
  summarize(
    mean_rate = mean(theft_rate),
    .groups = "drop"
  )

# Plot yearly means
ggplot(yearly_means, aes(x = year, y = mean_rate)) +
  geom_line(size = 1) +
  geom_point(size = 3, color = "blue") +
  geom_point(data = yearly_means |> filter(year == 2023), 
             aes(x = year, y = mean_rate), size = 4, color = "red") +
  labs(title = "Average Annual Car Theft Rates",
       x = "Year", y = "Average Thefts per 100,000 Population") +
  theme_minimal() +
  scale_x_continuous(breaks = 2017:2025)
```

## One-way ANOVA Analysis

### Hypothesis Formulation

For our ANOVA test, we'll compare the mean theft rates between the three time periods. First we need to create our hypotheses.

**Task 4** Fill in the hypotheses (2 points)

- **Null Hypothesis (H0)**: The mean car theft rates are equal across all three time periods.

- **Alternative Hypothesis (H1)**: The time periods have different mean car theft rates.

### One-way ANOVA Test

```{r anova-test}
# Perform one-way ANOVA on theft rates by time period
period_anova <- aov(theft_rate ~ time_period, data = theft_data)
summary(period_anova)
```

**Task 5** Describe the result: are there real differences in the average rates between the time periods? Is this result significant? (5 points)

The large F value (218) indicates that the variability between time periods is greater than the variability within groups. The p value is <2e-16 which is very small and is marked with the ***, showing the results are significant. This p value allows us to reject the null hypothesis meaning there are differences in the time periods (pre spike, spike and post spike).

ANSWER HERE

## Compare the differences between specific periods

Run our post-anova Tukey test and examine the results. 

```{r posthoc}
# Tukey's HSD test
tukey_results <- TukeyHSD(period_anova)
print(tukey_results)
```


```{r period-means}
# Visualize time period means with confidence intervals
period_rates <- theft_data |>
  group_by(time_period) |>
  summarize(
    mean_rate = mean(theft_rate),
    se = sd(theft_rate) / sqrt(n()),
    .groups = "drop"
  ) |>
  mutate(
    lower_ci = mean_rate - qt(0.975, n() - 1) * se,
    upper_ci = mean_rate + qt(0.975, n() - 1) * se
  )

# Ensure time period is ordered correctly
period_rates$time_period <- factor(period_rates$time_period, 
                                   levels = c("Pre-spike", "Spike year", "Post-spike"))

ggplot(period_rates, aes(x = time_period, y = mean_rate, fill = time_period)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.2) +
  labs(title = "Car Theft Rates by Time Period with 95% Confidence Intervals",
       x = "", y = "Mean Theft Rate per 100,000") +
  theme_minimal() +
  theme(legend.position = "none")
```

## Conclusion

This analysis has examined whether there are significant differences in car theft rates between the pre-spike period (before 2023), the spike year (2023), and the post-spike period (after 2023).

**Task 6** Describe the results of the Tukey's test and chart showing confidence intervals. Is there a significant difference between the three periods? In particular, is the difference between the pre-spike and post-spike periods real and significant? Write a headline and lede reporting these findings, focusing on the pre- and post-spike periods. (5 points)

There are significant differences in all three time periods. The confidence interval does not include 0 and the adjusted p value is 0, which is less than .05. 
When looking at the spike year vs post spike, the difference was 16.62, with the spike year being significantly higher. 
When looking at the spike year vs post spike there was a large difference of 36.76, meaning the spike year was much higher. 
Finally when looking at pre spike vs post spike periods, the differences are real and significant with post spike being 20.13 points higher than the pre spike. 

Headline/lede:

Car Theft Rates in Prince George's County Remain High After a Spike in 2023.

Statistical analysis shows that post-spike car thefts are on average about 20 thefts per 100,000 people higher than the pre-spike rate. 

ANSWER HERE
